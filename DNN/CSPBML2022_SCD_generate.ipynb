{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate SCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚙️  running on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 1: 100%|████████████████████████| 4000/4000 [00:32<00:00, 123.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ saved cached_scd_tim/2022_c_64_512sample_hamming/2022_batch_01.pt | X (4000, 64, 64)  y (4000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 2: 100%|████████████████████████| 4000/4000 [00:36<00:00, 109.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ saved cached_scd_tim/2022_c_64_512sample_hamming/2022_batch_02.pt | X (4000, 64, 64)  y (4000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 3: 100%|████████████████████████| 4000/4000 [00:33<00:00, 118.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ saved cached_scd_tim/2022_c_64_512sample_hamming/2022_batch_03.pt | X (4000, 64, 64)  y (4000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 4: 100%|████████████████████████| 4000/4000 [00:33<00:00, 119.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ saved cached_scd_tim/2022_c_64_512sample_hamming/2022_batch_04.pt | X (4000, 64, 64)  y (4000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 5: 100%|████████████████████████| 4000/4000 [00:32<00:00, 122.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ saved cached_scd_tim/2022_c_64_512sample_hamming/2022_batch_05.pt | X (4000, 64, 64)  y (4000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 6: 100%|████████████████████████| 4000/4000 [00:32<00:00, 121.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ saved cached_scd_tim/2022_c_64_512sample_hamming/2022_batch_06.pt | X (4000, 64, 64)  y (4000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 7: 100%|████████████████████████| 4000/4000 [00:31<00:00, 125.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ saved cached_scd_tim/2022_c_64_512sample_hamming/2022_batch_07.pt | X (4000, 64, 64)  y (4000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 8: 100%|████████████████████████| 4000/4000 [00:31<00:00, 128.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ saved cached_scd_tim/2022_c_64_512sample_hamming/2022_batch_08.pt | X (4000, 64, 64)  y (4000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 9: 100%|████████████████████████| 4000/4000 [00:31<00:00, 128.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ saved cached_scd_tim/2022_c_64_512sample_hamming/2022_batch_09.pt | X (4000, 64, 64)  y (4000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 10: 100%|███████████████████████| 4000/4000 [00:32<00:00, 124.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ saved cached_scd_tim/2022_c_64_512sample_hamming/2022_batch_10.pt | X (4000, 64, 64)  y (4000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 11: 100%|███████████████████████| 4000/4000 [00:30<00:00, 130.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ saved cached_scd_tim/2022_c_64_512sample_hamming/2022_batch_11.pt | X (4000, 64, 64)  y (4000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 12: 100%|███████████████████████| 4000/4000 [00:30<00:00, 129.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ saved cached_scd_tim/2022_c_64_512sample_hamming/2022_batch_12.pt | X (4000, 64, 64)  y (4000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 13: 100%|███████████████████████| 4000/4000 [00:30<00:00, 133.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ saved cached_scd_tim/2022_c_64_512sample_hamming/2022_batch_13.pt | X (4000, 64, 64)  y (4000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 14: 100%|███████████████████████| 4000/4000 [00:30<00:00, 131.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ saved cached_scd_tim/2022_c_64_512sample_hamming/2022_batch_14.pt | X (4000, 64, 64)  y (4000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 15: 100%|███████████████████████| 4000/4000 [00:29<00:00, 133.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ saved cached_scd_tim/2022_c_64_512sample_hamming/2022_batch_15.pt | X (4000, 64, 64)  y (4000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 16: 100%|███████████████████████| 4000/4000 [00:31<00:00, 125.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ saved cached_scd_tim/2022_c_64_512sample_hamming/2022_batch_16.pt | X (4000, 64, 64)  y (4000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 17: 100%|███████████████████████| 4000/4000 [00:31<00:00, 127.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ saved cached_scd_tim/2022_c_64_512sample_hamming/2022_batch_17.pt | X (4000, 64, 64)  y (4000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 18: 100%|███████████████████████| 4000/4000 [00:31<00:00, 128.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ saved cached_scd_tim/2022_c_64_512sample_hamming/2022_batch_18.pt | X (4000, 64, 64)  y (4000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 19: 100%|███████████████████████| 4000/4000 [00:31<00:00, 125.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ saved cached_scd_tim/2022_c_64_512sample_hamming/2022_batch_19.pt | X (4000, 64, 64)  y (4000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 20: 100%|███████████████████████| 4000/4000 [00:31<00:00, 125.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ saved cached_scd_tim/2022_c_64_512sample_hamming/2022_batch_20.pt | X (4000, 64, 64)  y (4000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 21: 100%|███████████████████████| 4000/4000 [00:31<00:00, 126.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ saved cached_scd_tim/2022_c_64_512sample_hamming/2022_batch_21.pt | X (4000, 64, 64)  y (4000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 22: 100%|███████████████████████| 4000/4000 [00:30<00:00, 129.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ saved cached_scd_tim/2022_c_64_512sample_hamming/2022_batch_22.pt | X (4000, 64, 64)  y (4000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 23: 100%|███████████████████████| 4000/4000 [00:31<00:00, 127.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ saved cached_scd_tim/2022_c_64_512sample_hamming/2022_batch_23.pt | X (4000, 64, 64)  y (4000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 24: 100%|███████████████████████| 4000/4000 [00:30<00:00, 130.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ saved cached_scd_tim/2022_c_64_512sample_hamming/2022_batch_24.pt | X (4000, 64, 64)  y (4000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 25: 100%|███████████████████████| 4000/4000 [00:31<00:00, 126.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ saved cached_scd_tim/2022_c_64_512sample_hamming/2022_batch_25.pt | X (4000, 64, 64)  y (4000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 26: 100%|███████████████████████| 4000/4000 [00:31<00:00, 128.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ saved cached_scd_tim/2022_c_64_512sample_hamming/2022_batch_26.pt | X (4000, 64, 64)  y (4000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 27: 100%|███████████████████████| 4000/4000 [00:29<00:00, 134.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ saved cached_scd_tim/2022_c_64_512sample_hamming/2022_batch_27.pt | X (4000, 64, 64)  y (4000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 28: 100%|███████████████████████| 4000/4000 [00:31<00:00, 126.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ saved cached_scd_tim/2022_c_64_512sample_hamming/2022_batch_28.pt | X (4000, 64, 64)  y (4000, 1)\n",
      "\n",
      "🏁 all finished in 14.84 min\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# scd_preprocess_tim_64.py\n",
    "# ------------------------------------------------------------\n",
    "# 依赖：PyTorch ≥2.0、SciPy、NumPy、tqdm\n",
    "# Usage : python scd_preprocess_tim_64.py\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "import os, gc, math, time\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from scipy.signal import decimate, chebwin\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 0. 全局常量\n",
    "# ------------------------------------------------------------\n",
    "torch.set_grad_enabled(False)\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"⚙️  running on {DEVICE}\")\n",
    "\n",
    "ROOT_TIM   = \"CSPB.ML_dataset/CSPB_ML_2022_Data\"   # 28 × 4000 个 .tim\n",
    "OUT_BASE   = \"cached_scd_tim\"                      # 总输出根目录\n",
    "# ---------------- 信号与窗参数 ----------------\n",
    "N          = 512           # 输入长度\n",
    "DECIMATE_Q = 64            # 32768 → 512\n",
    "Np, L, P   = 64, 16, 32    # 帧长 64，移位 16，共 32 帧\n",
    "NN         = (P - 1)*L + Np           # 560\n",
    "# ---------------- 数据集分块 ------------------\n",
    "N_BATCHES  = 28            # Batch_Dir_1 … Batch_Dir_28\n",
    "N_PER_DIR  = 4000          # 每批 4000 个信号\n",
    "DTYPE_OUT  = np.float32    # 保存精度\n",
    "# ---------------- 窗函数 (Chebyshev-64, at=100 dB) ----------\n",
    "#WIN64 = chebwin(64, at=100).astype(np.float32)   # (64,)\n",
    "w64 = np.hamming(64)     # 或 np.window.hamming(64) (NumPy ≥1.25)\n",
    "WIN64 = w64\n",
    "# ------------------------------------------------------------\n",
    "# 1. 工具函数\n",
    "# ------------------------------------------------------------\n",
    "def decimate_complex(x: np.ndarray, q: int = DECIMATE_Q) -> np.ndarray:\n",
    "    \"\"\"I、Q 分量独立 FIR + zero_phase 降采样，再合成复数\"\"\"\n",
    "    re = decimate(np.real(x), q, ftype='fir', zero_phase=True)\n",
    "    im = decimate(np.imag(x), q, ftype='fir', zero_phase=True)\n",
    "    return re + 1j * im\n",
    "\n",
    "def iq2_scd_matrix_torch(iq_512: torch.Tensor) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    输入：512 点复数 IQ（torch.complex64, on GPU）\n",
    "    输出：|SCD|² 结果 (16, 64*64) = (16, 4096)  numpy.float32\n",
    "    \"\"\"\n",
    "    # --------- zero-pad 到 NN = 560 ----------\n",
    "    if iq_512.numel() < NN:\n",
    "        pad = torch.zeros(NN - iq_512.numel(),\n",
    "                          dtype=iq_512.dtype, device=iq_512.device)\n",
    "        cfloat_signal = torch.cat([iq_512, pad])\n",
    "    else:\n",
    "        cfloat_signal = iq_512\n",
    "\n",
    "    # --------- 切 32 帧，每帧 64 点 ----------\n",
    "    X = torch.stack([cfloat_signal[k*L : k*L+Np] for k in range(P)], dim=1)  # (64,32)\n",
    "\n",
    "    # --------- 加窗 ----------\n",
    "    W = torch.tensor(WIN64, device=iq_512.device)[:, None]          # (64,1)\n",
    "    XW = W * X                                                      # (64,32)\n",
    "\n",
    "    # --------- 第一次 FFT ----------\n",
    "    XF1 = torch.fft.fft(XW, dim=0)            # (64,32)\n",
    "    XF1_shift = torch.cat([XF1[Np//2:], XF1[:Np//2]], dim=0)\n",
    "\n",
    "    # --------- 下变频 ----------\n",
    "    k = torch.arange(-Np//2, Np//2, device=iq_512.device)[:, None]  # (64,1)\n",
    "    idx = torch.arange(P, device=iq_512.device)[None, :]            # (1,32)\n",
    "    E = torch.exp(-1j * 2 * math.pi * k * idx * L / Np)             # (64,32)\n",
    "    XD = (XF1_shift * E).T                                          # (32,64)\n",
    "\n",
    "    # --------- 自互相关 & 第二次 FFT ----------\n",
    "    XM  = XD[:, :, None] * XD[:, None, :].conj()    # (32,64,64)\n",
    "    XM  = XM.reshape(P, -1)                         # (32,4096)\n",
    "    XF2 = torch.fft.fft(XM, dim=0)                  # (32,4096)\n",
    "    Z   = torch.abs(XF2) ** 2                       # (32,4096)\n",
    "\n",
    "    # --------- 拼接 16 周期段 ----------\n",
    "    out = torch.zeros((16, Z.shape[1]), device=iq_512.device)\n",
    "    out[:8] = Z[P//2 : 3*P//4]      # 16…23\n",
    "    out[8:] = Z[P//4 : P//2]        # 8…15\n",
    "    return out.cpu().numpy().astype(np.float32)\n",
    "\n",
    "def create_label():\n",
    "    \"\"\"返回 (4000,1) long 张量：0–7 重复 500 次\"\"\"\n",
    "    base = torch.tensor([0,1,2,3,4,5,6,7], dtype=torch.long)\n",
    "    y = base.repeat(500).reshape(-1,1)          # 8×500=4000\n",
    "    return y\n",
    "\n",
    "def tim_to_full64(tim_path: str) -> np.ndarray:\n",
    "    \"\"\"单个 .tim → 中心 64×64 SCD 热点矩阵 (float32)\"\"\"\n",
    "    raw = np.fromfile(tim_path, dtype=np.single)\n",
    "    iq_full = raw[2::2] + 1j * raw[3::2]          # 32768\n",
    "    iq_512  = decimate_complex(iq_full)           # 512\n",
    "    scd16   = iq2_scd_matrix_torch(\n",
    "        torch.from_numpy(iq_512.astype(np.complex64)).to(DEVICE)\n",
    "    )\n",
    "    return scd16[8].reshape(64, 64).T             # (64,64)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. 单批处理并保存 .pt\n",
    "# ------------------------------------------------------------\n",
    "def process_one_dir(batch_idx: int):\n",
    "    in_dir = os.path.join(ROOT_TIM, f\"Batch_Dir_{batch_idx}\")\n",
    "    X = torch.empty((N_PER_DIR, 64, 64), dtype=torch.float32)\n",
    "\n",
    "    for n in tqdm(range(1, N_PER_DIR + 1),\n",
    "                  desc=f\"Batch {batch_idx}\", ncols=75):\n",
    "        g = (batch_idx - 1) * N_PER_DIR + n\n",
    "        full64 = tim_to_full64(os.path.join(in_dir, f\"signal_{g}.tim\"))\n",
    "        X[n-1].copy_(torch.from_numpy(full64))\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    y = create_label()\n",
    "    out_dir  = os.path.join(OUT_BASE, \"2022_c_64_512sample_hamming\")\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    out_path = os.path.join(out_dir, f\"2022_batch_{batch_idx:02d}.pt\")\n",
    "    torch.save((X, y), out_path)\n",
    "    print(f\"saved {out_path} | X {tuple(X.shape)}  y {tuple(y.shape)}\")\n",
    "\n",
    "    del X, y; gc.collect()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3. 主入口\n",
    "# ------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    t0 = time.time()\n",
    "    for idx in range(1, N_BATCHES + 1):\n",
    "        process_one_dir(idx)\n",
    "    print(f\"\\n🏁 all finished in {(time.time() - t0)/60:.2f} min\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1493018,
     "sourceId": 2468162,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2859031,
     "sourceId": 4930249,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7020230,
     "sourceId": 11237252,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 292809,
     "modelInstanceId": 271817,
     "sourceId": 322552,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
